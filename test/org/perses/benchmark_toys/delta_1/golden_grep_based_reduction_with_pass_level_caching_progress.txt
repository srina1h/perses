=====================Reduction starts.======================

The initial program size is 56
The command line options are:
---
helpFlags:
  groupName: "Help"
  help: false
verbosityFlags:
  groupName: "Verbosity"
  verbosity: "INFO"
  listVerbosity: false
versionFlags:
  groupName: "Version"
  version: false
inputFlags:
  groupName: "Inputs"
  testScript: "grep_based_r.sh"
  inputFile: "t.c"
  deps: []
  sourceFile: "t.c"
resultOutputFlags:
  groupName: "Outputs"
  outputDir: "result_grep_based_token_reduction_with_pass_level_cache_golden_test_concurrent_token_slicer_t.c"
reductionControlFlags:
  groupName: "General Reduction Control"
  fixpoint: true
  numOfThreads: 1
  codeFormat: "COMPACT_ORIG_FORMAT"
  testScriptExecutionTimeoutInSeconds: 600
  testScriptExecutionKeepWaitingAfterTimeout: true
outputRefiningFlags:
  groupName: "Output Refining Control"
  callFormatter: false
  formatCmd: ""
  callCReduce: false
  creduceCmd: "creduce"
algorithmControlFlags:
  groupName: "Reduction Algorithm Control"
  reductionAlgorithm: "concurrent_token_slicer"
  listAllReductionAlgorithms: false
  rebuildParseTreeEachIteration: true
  enableTokenSlicer: true
  enableTreeSlicer: true
  enableLineSlicer: true
  defaultDeltaDebuggerTypeForKleene: "DFS"
  maxEditCountForRegularRuleNode: 100
  maxBfsDepthForRegularRuleNode: 5
  stopAtFirstCompatibleChildForRegularRuleNode: false
languageControlFlags:
  groupName: "Language Control"
  languageName: ""
  listLangs: false
  designatedParserFacadeClassName: ""
  listParserFacades: false
  languageJarFiles: []
vulcanFlags:
  groupName: "Vulcan Reducer Control"
  enableVulcan: false
  nonDeletionIterationLimit: 10
  windowSize: 4
  vulcanFixpoint: false
trecFlags:
  groupName: "T-Rec Reducer Control"
  enableTrec: false
profilingFlags:
  groupName: "Profiling"
  progressDumpFile: "grep_based_reduction_with_pass_level_cache_progress.txt"
  appendToProgressDumpFile: true
  statDumpFile: null
  profileQueryCacheTime: null
  profileQueryCacheTimeCSV: null
  profileQueryCacheMemory: null
  actionSetProfiler: null
  profileDeltaDebugger: null
cacheControlFlags:
  groupName: "Cache Control"
  queryCaching: "FALSE"
  cacheType: "CONTENT_SHA512"
  nodeActionSetCaching: false
  queryCacheRefreshThreshold: 0
  enableLightweightRefreshing: true
  enablePassCache: true
  globalCacheFile: null
  pathToSaveUpdatedGlobalCache: null
experimentFlags:
  groupName: "Experiment Control"
  onDemandFineGritReducerAnnotationClasses: []
  onDemandMediumGritReducerAnnotationClasses: []
  onDemandCoarseGritReducerAnnotationClasses: []
lprFlags:
  groupName: "LPR Reducer Control"
  enableLPR: false
  lprFixpoint: false
  llmClientPath: null

Parser Facade: class org.perses.grammar.c.PnfCParserFacade
------------------------------------------------------------


The sanity check has been performed. The result is PassingSanityCheckResult
The reducer execution plan is listed below.
--- !<sequence>
reducers:
- !<fixpoint>
  body: !<atomic>
    reducer: concurrent_token_slicer
  condition: smaller
- !<sequence>
  reducers:
  - !<fixpoint>
    body: !<if>
      condition: !<atomic>
        reducer: line_based_concurrent_token_slicer
      then: !<fixpoint>
        body: !<atomic>
          reducer: concurrent_token_slicer
        condition: smaller
    condition: smaller
  - !<fixpoint>
    body: !<if>
      condition: !<atomic>
        reducer: tree_slicer
      then: !<fixpoint>
        body: !<atomic>
          reducer: concurrent_token_slicer
        condition: smaller
    condition: smaller
  - !<fixpoint>
    body: !<if>
      condition: !<atomic>
        reducer: concurrent_token_slicer
      then: !<fixpoint>
        body: !<atomic>
          reducer: concurrent_token_slicer
        condition: smaller
    condition: smaller


Rebuilding spar-tree: The spartree is not dirty, and thus the rebuilding is skipped.

==Fixpoint iteration 1. Reducer: concurrent_token_slicer@1==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |   |   |___directDeclarator {id=367,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator]}
    |   |       |___Token:printf {id=398,slot_type=[aux_rule__directDeclarator_9,Identifier]}
    |   |       |___(*) {id=369,slot_type=kleene_star__directDeclarator_7}
    |   |           |___aux_rule__directDeclarator_15 {id=371,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_15]}
    |   |               |___Token:( {id=372,slot_type=LeftParen}
    |   |               |___parameterTypeList {id=375,slot_type=[altnt_block__directDeclarator_11,parameterTypeList]}
    |   |               |   |___parameterDeclaration {id=381,slot_type=[parameterList,parameterDeclaration]}
    |   |               |   |   |___(+) {id=382,slot_type=declarationSpecifiers}
    |   |               |   |   |   |___Token:const {id=397,slot_type=[declarationSpecifier,typeQualifier,Const]}
    |   |               |   |   |   |___Token:char {id=395,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Char]}
    |   |               |   |   |___(?) {id=384,slot_type=[altnt_block__parameterDeclaration_2,optional__typeName_1]}
    |   |               |   |       |___(+) {id=387,slot_type=[abstractDeclarator,pointer,kleene_plus__pointer_8]}
    |   |               |   |           |___Token:* {id=390,slot_type=[aux_rule__pointer_6,altnt_block__pointer_9,Star]}
    |   |               |   |___(?) {id=377,slot_type=optional__parameterTypeList_2}
    |   |               |       |___aux_rule__parameterTypeList_1 {id=378,slot_type=aux_rule__parameterTypeList_1}
    |   |               |           |___Token:, {id=379,slot_type=Comma}
    |   |               |           |___Token:... {id=380,slot_type=Ellipsis}
    |   |               |___Token:) {id=374,slot_type=RightParen}
    |   |___Token:; {id=363,slot_type=Semi}
    |___functionDefinition {id=5,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___(?) {id=6,slot_type=optional__functionDefinition_2}
        |   |___(+) {id=354,slot_type=declarationSpecifiers}
        |       |___Token:int {id=358,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
        |___directDeclarator {id=303,slot_type=[declarator,directDeclarator]}
        |   |___Token:main {id=353,slot_type=[aux_rule__directDeclarator_9,Identifier]}
        |   |___(*) {id=305,slot_type=kleene_star__directDeclarator_7}
        |       |___aux_rule__directDeclarator_15 {id=307,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_15]}
        |           |___Token:( {id=308,slot_type=LeftParen}
        |           |___parameterList {id=312,slot_type=[altnt_block__directDeclarator_11,parameterTypeList,parameterList]}
        |           |   |___(+) {id=342,slot_type=[parameterDeclaration,declarationSpecifiers]}
        |           |   |   |___Token:int {id=352,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
        |           |   |   |___Token:argc {id=349,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,typedefName,Identifier]}
        |           |   |___(*) {id=314,slot_type=kleene_star__parameterList_1}
        |           |       |___aux_rule__parameterList_2 {id=315,slot_type=aux_rule__parameterList_2}
        |           |           |___Token:, {id=316,slot_type=Comma}
        |           |           |___parameterDeclaration {id=317,slot_type=parameterDeclaration}
        |           |               |___(+) {id=318,slot_type=declarationSpecifiers}
        |           |               |   |___Token:char {id=341,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Char]}
        |           |               |___declarator {id=320,slot_type=[altnt_block__parameterDeclaration_2,declarator]}
        |           |                   |___(?) {id=321,slot_type=optional__declarator_1}
        |           |                   |   |___(+) {id=334,slot_type=[pointer,kleene_plus__pointer_8]}
        |           |                   |       |___Token:* {id=337,slot_type=[aux_rule__pointer_6,altnt_block__pointer_9,Star]}
        |           |                   |___directDeclarator {id=322,slot_type=directDeclarator}
        |           |                       |___Token:argv {id=332,slot_type=[aux_rule__directDeclarator_9,Identifier]}
        |           |                       |___(*) {id=324,slot_type=kleene_star__directDeclarator_7}
        |           |                           |___aux_rule__directDeclarator_14 {id=326,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_14]}
        |           |                               |___Token:[ {id=327,slot_type=LeftBracket}
        |           |                               |___Token:] {id=329,slot_type=RightBracket}
        |           |___Token:) {id=310,slot_type=RightParen}
        |___compoundStatement {id=8,slot_type=compoundStatement}
            |___Token:{ {id=9,slot_type=LeftBrace}
            |___(?) {id=10,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___aux_rule__declaration_3 {id=267,slot_type=[aux_rule__blockItemList_2,declaration,aux_rule__declaration_3]}
            |       |   |___(+) {id=268,slot_type=declarationSpecifiers}
            |       |   |   |___Token:int {id=302,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
            |       |   |___(?) {id=269,slot_type=optional__declaration_2}
            |       |   |   |___initDeclarator {id=272,slot_type=[initDeclaratorList,initDeclarator]}
            |       |   |       |___Token:a {id=298,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
            |       |   |       |___(?) {id=274,slot_type=optional__initDeclarator_2}
            |       |   |           |___aux_rule__initDeclarator_1 {id=275,slot_type=aux_rule__initDeclarator_1}
            |       |   |               |___Token:= {id=276,slot_type=Assign}
            |       |   |               |___Token:1 {id=295,slot_type=[initializer,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Constant]}
            |       |   |___Token:; {id=270,slot_type=Semi}
            |       |___aux_rule__declaration_3 {id=219,slot_type=[aux_rule__blockItemList_2,declaration,aux_rule__declaration_3]}
            |       |   |___(+) {id=220,slot_type=declarationSpecifiers}
            |       |   |   |___Token:int {id=265,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
            |       |   |___(?) {id=221,slot_type=optional__declaration_2}
            |       |   |   |___initDeclarator {id=224,slot_type=[initDeclaratorList,initDeclarator]}
            |       |   |       |___Token:b {id=261,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
            |       |   |       |___(?) {id=226,slot_type=optional__initDeclarator_2}
            |       |   |           |___aux_rule__initDeclarator_1 {id=227,slot_type=aux_rule__initDeclarator_1}
            |       |   |               |___Token:= {id=228,slot_type=Assign}
            |       |   |               |___additiveExpression {id=240,slot_type=[initializer,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression]}
            |       |   |                   |___Token:a {id=258,slot_type=[multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Identifier]}
            |       |   |                   |___(*) {id=242,slot_type=kleene_star__additiveExpression_1}
            |       |   |                       |___aux_rule__additiveExpression_2 {id=243,slot_type=aux_rule__additiveExpression_2}
            |       |   |                           |___Token:+ {id=252,slot_type=[altnt_block__additiveExpression_3,Plus]}
            |       |   |                           |___Token:1 {id=251,slot_type=[multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Constant]}
            |       |   |___Token:; {id=222,slot_type=Semi}
            |       |___expressionStatement {id=149,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |       |   |___(?) {id=150,slot_type=optional__postfixExpression_1}
            |       |   |   |___postfixExpression {id=168,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression]}
            |       |   |       |___Token:printf {id=217,slot_type=[aux_rule__postfixExpression_4,Identifier]}
            |       |   |       |___(*) {id=170,slot_type=kleene_star__postfixExpression_2}
            |       |   |           |___aux_rule__postfixExpression_11 {id=172,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |   |               |___Token:( {id=173,slot_type=LeftParen}
            |       |   |               |___(?) {id=174,slot_type=optional__postfixExpression_1}
            |       |   |               |   |___expression {id=176,slot_type=expression}
            |       |   |               |       |___(+) {id=215,slot_type=[assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |   |               |       |   |___Token:"%d\n" {id=216,slot_type=StringLiteral}
            |       |   |               |       |___(*) {id=178,slot_type=kleene_star__expression_1}
            |       |   |               |           |___aux_rule__expression_2 {id=179,slot_type=aux_rule__expression_2}
            |       |   |               |               |___Token:, {id=180,slot_type=Comma}
            |       |   |               |               |___Token:b {id=198,slot_type=[assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Identifier]}
            |       |   |               |___Token:) {id=175,slot_type=RightParen}
            |       |   |___Token:; {id=151,slot_type=Semi}
            |       |___expressionStatement {id=99,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |       |   |___(?) {id=100,slot_type=optional__postfixExpression_1}
            |       |   |   |___postfixExpression {id=118,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression]}
            |       |   |       |___Token:printf {id=146,slot_type=[aux_rule__postfixExpression_4,Identifier]}
            |       |   |       |___(*) {id=120,slot_type=kleene_star__postfixExpression_2}
            |       |   |           |___aux_rule__postfixExpression_11 {id=122,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |   |               |___Token:( {id=123,slot_type=LeftParen}
            |       |   |               |___(?) {id=124,slot_type=optional__postfixExpression_1}
            |       |   |               |   |___(+) {id=144,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |   |               |       |___Token:"hello\n" {id=145,slot_type=StringLiteral}
            |       |   |               |___Token:) {id=125,slot_type=RightParen}
            |       |   |___Token:; {id=101,slot_type=Semi}
            |       |___expressionStatement {id=49,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |       |   |___(?) {id=50,slot_type=optional__postfixExpression_1}
            |       |   |   |___postfixExpression {id=68,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression]}
            |       |   |       |___Token:printf {id=96,slot_type=[aux_rule__postfixExpression_4,Identifier]}
            |       |   |       |___(*) {id=70,slot_type=kleene_star__postfixExpression_2}
            |       |   |           |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |   |               |___Token:( {id=73,slot_type=LeftParen}
            |       |   |               |___(?) {id=74,slot_type=optional__postfixExpression_1}
            |       |   |               |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |   |               |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
            |       |   |               |___Token:) {id=75,slot_type=RightParen}
            |       |   |___Token:; {id=51,slot_type=Semi}
            |       |___jumpStatement {id=22,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement]}
            |           |___aux_rule__jumpStatement_4 {id=25,slot_type=[altnt_block__jumpStatement_2,aux_rule__jumpStatement_4]}
            |           |   |___Token:return {id=26,slot_type=Return}
            |           |   |___(?) {id=27,slot_type=optional__postfixExpression_1}
            |           |       |___Token:0 {id=46,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Constant]}
            |           |___Token:; {id=24,slot_type=Semi}
            |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
        return 0;
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
        return 0;
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
        return 0
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
        return 0
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
        return  ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
        return  ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 56 -> 55
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n");
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 55 -> 54
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 54 -> 53
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n"
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf("world\n"
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf(         )
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf(         )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
     printf "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n");
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 53 -> 52
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n")
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n")
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 52 -> 51
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n"
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf("hello\n"
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 51 -> 50
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf          )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
     printf          )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
           (         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b);
           (         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b)
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b)
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b ;
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n", b ;
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n",  );
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n",  );
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n"  b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf("%d\n"  b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf(      , b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf(      , b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf "%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
     printf "%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1;
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 50 -> 49
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a + 1
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 49 -> 48
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a +
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a +
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 48 -> 47
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b = a
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 47 -> 46
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 46 -> 45
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int b
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int   =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
              int   =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 45 -> 44
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a = 1
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a =  ;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a =  ;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a   1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int a   1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int   = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
         int   = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 44 -> 43
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[])
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[])
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[]  {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[]  {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv[ ) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv[ ) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *argv ]) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *argv ]) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char *    []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char *    []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 43 -> 42
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc, char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc, char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 42 -> 41
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc,           []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc,           []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int argc  char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int argc  char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 41 -> 40
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (int       char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (int       char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 40 -> 39
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 39 -> 38
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int main            char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int main            char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
    int      (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
    int      (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 38 -> 37
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ...)
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ...)
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*, ... ;
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*, ... ;
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*,    );
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*,    );
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char*  ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char*  ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const char , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const char , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 37 -> 36
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 36 -> 35
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf(           , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(           , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int       (const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int       (const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
                ;
    }
------------------------------------------------------------


==Fixpoint iteration 2. Reducer: concurrent_token_slicer@2==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |   |   |___directDeclarator {id=367,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator]}
    |   |       |___Token:printf {id=398,slot_type=[aux_rule__directDeclarator_9,Identifier]}
    |   |       |___(*) {id=369,slot_type=kleene_star__directDeclarator_7}
    |   |           |___aux_rule__directDeclarator_15 {id=371,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_15]}
    |   |               |___Token:( {id=372,slot_type=LeftParen}
    |   |               |___parameterTypeList {id=375,slot_type=[altnt_block__directDeclarator_11,parameterTypeList]}
    |   |               |   |___(+) {id=382,slot_type=[parameterList,parameterDeclaration,declarationSpecifiers]}
    |   |               |   |   |___Token:const {id=397,slot_type=[declarationSpecifier,typeQualifier,Const]}
    |   |               |   |___(?) {id=377,slot_type=optional__parameterTypeList_2}
    |   |               |       |___aux_rule__parameterTypeList_1 {id=378,slot_type=aux_rule__parameterTypeList_1}
    |   |               |           |___Token:, {id=379,slot_type=Comma}
    |   |               |           |___Token:... {id=380,slot_type=Ellipsis}
    |   |               |___Token:) {id=374,slot_type=RightParen}
    |   |___Token:; {id=363,slot_type=Semi}
    |___functionDefinition {id=5,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___directDeclarator {id=303,slot_type=[declarator,directDeclarator]}
        |   |___Token:main {id=353,slot_type=[aux_rule__directDeclarator_9,Identifier]}
        |   |___(*) {id=305,slot_type=kleene_star__directDeclarator_7}
        |       |___aux_rule__directDeclarator_15 {id=307,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_15]}
        |           |___Token:( {id=308,slot_type=LeftParen}
        |           |___(*) {id=314,slot_type=[altnt_block__directDeclarator_11,parameterTypeList,parameterList,kleene_star__parameterList_1]}
        |           |   |___parameterDeclaration {id=317,slot_type=[aux_rule__parameterList_2,parameterDeclaration]}
        |           |       |___(+) {id=318,slot_type=declarationSpecifiers}
        |           |       |   |___Token:char {id=341,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Char]}
        |           |       |___(*) {id=324,slot_type=[altnt_block__parameterDeclaration_2,declarator,directDeclarator,kleene_star__directDeclarator_7]}
        |           |           |___aux_rule__directDeclarator_14 {id=326,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_14]}
        |           |               |___Token:[ {id=327,slot_type=LeftBracket}
        |           |               |___Token:] {id=329,slot_type=RightBracket}
        |           |___Token:) {id=310,slot_type=RightParen}
        |___compoundStatement {id=8,slot_type=compoundStatement}
            |___Token:{ {id=9,slot_type=LeftBrace}
            |___(?) {id=10,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___aux_rule__declaration_3 {id=267,slot_type=[aux_rule__blockItemList_2,declaration,aux_rule__declaration_3]}
            |       |   |___(?) {id=269,slot_type=optional__declaration_2}
            |       |   |   |___initDeclarator {id=272,slot_type=[initDeclaratorList,initDeclarator]}
            |       |   |       |___Token:a {id=298,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
            |       |   |       |___(?) {id=274,slot_type=optional__initDeclarator_2}
            |       |   |           |___aux_rule__initDeclarator_1 {id=275,slot_type=aux_rule__initDeclarator_1}
            |       |   |               |___Token:= {id=276,slot_type=Assign}
            |       |   |               |___Token:1 {id=295,slot_type=[initializer,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Constant]}
            |       |   |___Token:; {id=270,slot_type=Semi}
            |       |___(?) {id=221,slot_type=[aux_rule__blockItemList_2,declaration,aux_rule__declaration_3,optional__declaration_2]}
            |       |   |___initDeclarator {id=224,slot_type=[initDeclaratorList,initDeclarator]}
            |       |       |___Token:b {id=261,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
            |       |       |___(?) {id=226,slot_type=optional__initDeclarator_2}
            |       |           |___Token:= {id=228,slot_type=[aux_rule__initDeclarator_1,Assign]}
            |       |___expressionStatement {id=149,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |       |   |___(?) {id=150,slot_type=optional__postfixExpression_1}
            |       |   |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
            |       |   |       |___aux_rule__postfixExpression_11 {id=172,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |   |           |___Token:( {id=173,slot_type=LeftParen}
            |       |   |           |___(?) {id=174,slot_type=optional__postfixExpression_1}
            |       |   |           |   |___expression {id=176,slot_type=expression}
            |       |   |           |       |___(+) {id=215,slot_type=[assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |   |           |       |   |___Token:"%d\n" {id=216,slot_type=StringLiteral}
            |       |   |           |       |___(*) {id=178,slot_type=kleene_star__expression_1}
            |       |   |           |           |___aux_rule__expression_2 {id=179,slot_type=aux_rule__expression_2}
            |       |   |           |               |___Token:, {id=180,slot_type=Comma}
            |       |   |           |               |___Token:b {id=198,slot_type=[assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,Identifier]}
            |       |   |           |___Token:) {id=175,slot_type=RightParen}
            |       |   |___Token:; {id=151,slot_type=Semi}
            |       |___(?) {id=100,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
            |       |   |___postfixExpression {id=118,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression]}
            |       |       |___Token:printf {id=146,slot_type=[aux_rule__postfixExpression_4,Identifier]}
            |       |       |___(*) {id=120,slot_type=kleene_star__postfixExpression_2}
            |       |           |___aux_rule__postfixExpression_11 {id=122,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |               |___Token:( {id=123,slot_type=LeftParen}
            |       |               |___Token:) {id=125,slot_type=RightParen}
            |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
            |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
            |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |           |___Token:( {id=73,slot_type=LeftParen}
            |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
            |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
            |       |           |___Token:) {id=75,slot_type=RightParen}
            |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
            |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n")
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n"
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           ("world\n"
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           (
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
           (
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(         )
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
     printf(
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 35 -> 33
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b);
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b)
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n", b)
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 33 -> 31
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n",
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n",
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 31 -> 29
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
                     )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b =
                     )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b
            "%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
                  b
            "%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a = 1;
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 29 -> 27
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
             a =
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
             a =
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 27 -> 25
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 25 -> 23
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      []
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      []
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char      [   {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char      [   {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 23 -> 21
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
        main                        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
        main                        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...);
                        char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...);
                        char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      , ...)
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      , ...)
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 21 -> 19
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const      ,
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const      ,
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 19 -> 17
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int printf                 )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf                 )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
    int        const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int        const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
              (const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
              (const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n")
                ;
    }
------------------------------------------------------------


==Fixpoint iteration 3. Reducer: concurrent_token_slicer@3==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___directDeclarator {id=367,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator]}
    |           |___Token:printf {id=398,slot_type=[aux_rule__directDeclarator_9,Identifier]}
    |           |___(*) {id=369,slot_type=kleene_star__directDeclarator_7}
    |               |___aux_rule__directDeclarator_15 {id=371,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_15]}
    |                   |___Token:( {id=372,slot_type=LeftParen}
    |                   |___(+) {id=382,slot_type=[altnt_block__directDeclarator_11,parameterTypeList,parameterList,parameterDeclaration,declarationSpecifiers]}
    |                   |   |___Token:const {id=397,slot_type=[declarationSpecifier,typeQualifier,Const]}
    |                   |___Token:) {id=374,slot_type=RightParen}
    |___functionDefinition {id=5,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___(*) {id=305,slot_type=[declarator,directDeclarator,kleene_star__directDeclarator_7]}
        |   |___aux_rule__directDeclarator_15 {id=307,slot_type=[aux_rule__directDeclarator_8,aux_rule__directDeclarator_15]}
        |       |___Token:( {id=308,slot_type=LeftParen}
        |       |___(*) {id=314,slot_type=[altnt_block__directDeclarator_11,parameterTypeList,parameterList,kleene_star__parameterList_1]}
        |       |   |___(+) {id=318,slot_type=[aux_rule__parameterList_2,parameterDeclaration,declarationSpecifiers]}
        |       |       |___Token:char {id=341,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Char]}
        |       |___Token:) {id=310,slot_type=RightParen}
        |___compoundStatement {id=8,slot_type=compoundStatement}
            |___Token:{ {id=9,slot_type=LeftBrace}
            |___(?) {id=10,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
            |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
            |       |       |___aux_rule__postfixExpression_11 {id=172,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |           |___Token:( {id=173,slot_type=LeftParen}
            |       |           |___(?) {id=174,slot_type=optional__postfixExpression_1}
            |       |           |   |___(+) {id=215,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |           |       |___Token:"%d\n" {id=216,slot_type=StringLiteral}
            |       |           |___Token:) {id=175,slot_type=RightParen}
            |       |___(?) {id=100,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
            |       |   |___(*) {id=120,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
            |       |       |___Token:( {id=123,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
            |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
            |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
            |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
            |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
            |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
            |       |           |___Token:) {id=75,slot_type=RightParen}
            |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
            |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n"
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
           (
            "world\n"
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
           (
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
           (
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char        ) {
           ("%d\n"   )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (          char        ) {
           ("%d\n"
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char        ) {
           ("%d\n"
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (          char        ) {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char        ) {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 17 -> 14
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (          char
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (          char
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
             (
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
             (
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf(const           )
                                      {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf(const           )
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 14 -> 11
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@3
    --file: t.c--
    int printf
                                      {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 11 -> 8
------------------------------------------------------------


==Fixpoint iteration 4. Reducer: concurrent_token_slicer@4==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
    int printf
                                      {
           (
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
           (
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
    int printf
                                      {
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
    int printf
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
    int
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
            "world\n")
                ;
    }
------------------------------------------------------------


==Fixpoint iteration 5. Reducer: concurrent_token_slicer@5==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
    int printf
                                      {
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
    int printf
    }
    --file: <formatted tokenized program in its original format>--
    int printf
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
    int
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
                     )
                ;
    }
------------------------------------------------------------


==Fixpoint iteration 6. Reducer: concurrent_token_slicer@6==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@6
    --file: t.c--
    int printf
    --file: <formatted tokenized program in its original format>--
    int printf
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@6
    --file: t.c--
    int
    }
    --file: <formatted tokenized program in its original format>--
    int
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@6
    --file: t.c--
                ;
    }
    --file: <formatted tokenized program in its original format>--
                ;
    }
------------------------------------------------------------


==Fixpoint iteration 7. Reducer: concurrent_token_slicer@7==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@7
    --file: t.c--
    int
    --file: <formatted tokenized program in its original format>--
    int
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@7
    --file: t.c--
    }
    --file: <formatted tokenized program in its original format>--
    }
------------------------------------------------------------


==Fixpoint iteration 8. Reducer: concurrent_token_slicer@8==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@8
    --file: t.c--
    --file: <formatted tokenized program in its original format>--
------------------------------------------------------------


==Fixpoint iteration 9. Reducer: concurrent_token_slicer@9==

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 10. Reducer: concurrent_token_slicer@10=

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 11. Reducer: concurrent_token_slicer@11=

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 12. Reducer: concurrent_token_slicer@12=

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 13. Reducer: concurrent_token_slicer@13=

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 14. Reducer: concurrent_token_slicer@14=

The spar-tree is the following.
translationUnit {id=1,slot_type=translationUnit}
|___(+) {id=2,slot_type=kleene_plus__translationUnit_3}
    |___aux_rule__declaration_3 {id=360,slot_type=[aux_rule__translationUnit_2,declaration,aux_rule__declaration_3]}
    |   |___(+) {id=361,slot_type=declarationSpecifiers}
    |   |   |___Token:int {id=402,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
    |   |___(?) {id=362,slot_type=optional__declaration_2}
    |       |___Token:printf {id=398,slot_type=[initDeclaratorList,initDeclarator,declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
    |___compoundStatement {id=8,slot_type=[aux_rule__translationUnit_2,functionDefinition,compoundStatement]}
        |___Token:{ {id=9,slot_type=LeftBrace}
        |___(?) {id=10,slot_type=optional__compoundStatement_1}
        |   |___(+) {id=13,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
        |       |___(?) {id=150,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=170,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___Token:( {id=173,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11,LeftParen]}
        |       |___(?) {id=50,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement,optional__postfixExpression_1]}
        |       |   |___(*) {id=70,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,kleene_star__postfixExpression_2]}
        |       |       |___aux_rule__postfixExpression_11 {id=72,slot_type=[aux_rule__postfixExpression_3,aux_rule__postfixExpression_11]}
        |       |           |___(?) {id=74,slot_type=optional__postfixExpression_1}
        |       |           |   |___(+) {id=94,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
        |       |           |       |___Token:"world\n" {id=95,slot_type=StringLiteral}
        |       |           |___Token:) {id=75,slot_type=RightParen}
        |       |___Token:; {id=24,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,jumpStatement,Semi]}
        |___Token:} {id=11,slot_type=RightBrace}
------------------------------------------------------------


Rebuilding spar-tree: The spartree is rebuilt.

=Fixpoint iteration 15. Reducer: concurrent_token_slicer@1==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___(?) {id=408,slot_type=optional__functionDefinition_2}
        |   |___(+) {id=468,slot_type=declarationSpecifiers}
        |       |___Token:int {id=472,slot_type=[declarationSpecifier,typeSpecifierWithAttrList,typeSpecifier,Int]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf
                                      {
           (
            "world\n")
                ;
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
           (
            "world\n")
                ;
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf
                                      {
           (
            "world\n")
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
           (
            "world\n")
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf
                                      {
           (
            "world\n"
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
           (
            "world\n"
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf
                                      {
           (
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
           (
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf
                                      {
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf
                                      {
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int printf
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int printf
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
    int
                                      {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
    int
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: pass=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===========TestScriptExecutionCacheEntryEviction============

0 entries are removed: 0 --> 0.
------------------------------------------------------------


===========Node edit action set cache is cleared.===========

    size before clearance = 0
------------------------------------------------------------


================The best program is updated.================

token count change 8 -> 7
------------------------------------------------------------


=Fixpoint iteration 16. Reducer: concurrent_token_slicer@2==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
        printf
                                      {
           (
            "world\n")
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
        printf
                                      {
           (
            "world\n"
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n"
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
        printf
                                      {
           (
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
        printf
                                      {
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
        printf
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@2
    --file: t.c--
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
           (
            "world\n")
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 17. Reducer: concurrent_token_slicer@3==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
        printf
                                      {
           (
            "world\n"
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n"
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
        printf
                                      {
           (
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
        printf
                                      {
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
        printf
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@3
    --file: t.c--
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
            "world\n")
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 18. Reducer: concurrent_token_slicer@4==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
        printf
                                      {
           (
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
        printf
                                      {
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
        printf
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@4
    --file: t.c--
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
                     )
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 19. Reducer: concurrent_token_slicer@5==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
        printf
                                      {
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
        printf
    }
    --file: <formatted tokenized program in its original format>--
        printf
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@5
    --file: t.c--
                ;
    }
    --file: <formatted tokenized program in its original format>--
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 20. Reducer: concurrent_token_slicer@6==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@6
    --file: t.c--
        printf
    --file: <formatted tokenized program in its original format>--
        printf
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@6
    --file: t.c--
    }
    --file: <formatted tokenized program in its original format>--
    }
------------------------------------------------------------


=Fixpoint iteration 21. Reducer: concurrent_token_slicer@7==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@7
    --file: t.c--
    --file: <formatted tokenized program in its original format>--
------------------------------------------------------------


=Fixpoint iteration 22. Reducer: concurrent_token_slicer@8==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 23. Reducer: concurrent_token_slicer@9==

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 24. Reducer: concurrent_token_slicer@10=

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 25. Reducer: concurrent_token_slicer@11=

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 26. Reducer: concurrent_token_slicer@12=

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 27. Reducer: concurrent_token_slicer@13=

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 28. Reducer: concurrent_token_slicer@14=

The spar-tree is the following.
translationUnit {id=404,slot_type=translationUnit}
|___(+) {id=405,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=407,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=467,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=410,slot_type=compoundStatement}
            |___Token:{ {id=411,slot_type=LeftBrace}
            |___(?) {id=412,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=415,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=419,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=420,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=440,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=443,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=444,slot_type=LeftParen}
            |           |       |   |___(+) {id=463,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=464,slot_type=StringLiteral}
            |           |       |___Token:) {id=442,slot_type=RightParen}
            |           |___Token:; {id=421,slot_type=Semi}
            |___Token:} {id=413,slot_type=RightBrace}
------------------------------------------------------------


Rebuilding spar-tree: The spartree is rebuilt.

=Fixpoint iteration 29. Reducer: concurrent_token_slicer@1==

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
                ;
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
                                      {
           (
            "world\n")
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
                                      {
           (
            "world\n"
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n"
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
                                      {
           (
                     )
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
                     )
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
                                      {
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
        printf
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: token slicer@1
    --file: t.c--
                                      {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 30. Reducer: line_based_concurrent_token_slicer@1

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@1
    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
                ;
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@1
    --file: t.c--
        printf
                                      {
           (
            "world\n")
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@1
    --file: t.c--
        printf
                                      {
           (
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@1
    --file: t.c--
        printf
                                      {
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@1
    --file: t.c--
        printf
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@1
    --file: t.c--
                                      {
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 31. Reducer: line_based_concurrent_token_slicer@2

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@2
    --file: t.c--
        printf
                                      {
           (
            "world\n")
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
            "world\n")
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@2
    --file: t.c--
        printf
                                      {
           (
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@2
    --file: t.c--
        printf
                                      {
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@2
    --file: t.c--
        printf
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@2
    --file: t.c--
           (
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
           (
            "world\n")
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 32. Reducer: line_based_concurrent_token_slicer@3

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@3
    --file: t.c--
        printf
                                      {
           (
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
           (
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@3
    --file: t.c--
        printf
                                      {
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@3
    --file: t.c--
        printf
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@3
    --file: t.c--
            "world\n")
                ;
    }
    --file: <formatted tokenized program in its original format>--
            "world\n")
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 33. Reducer: line_based_concurrent_token_slicer@4

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@4
    --file: t.c--
        printf
                                      {
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@4
    --file: t.c--
        printf
    }
    --file: <formatted tokenized program in its original format>--
        printf
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@4
    --file: t.c--
                ;
    }
    --file: <formatted tokenized program in its original format>--
                ;
    }
------------------------------------------------------------


=Fixpoint iteration 34. Reducer: line_based_concurrent_token_slicer@5

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@5
    --file: t.c--
        printf
    --file: <formatted tokenized program in its original format>--
        printf
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@5
    --file: t.c--
    }
    --file: <formatted tokenized program in its original format>--
    }
------------------------------------------------------------


=Fixpoint iteration 35. Reducer: line_based_concurrent_token_slicer@6

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: line slicer@6
    --file: t.c--
    --file: <formatted tokenized program in its original format>--
------------------------------------------------------------


=Fixpoint iteration 36. Reducer: line_based_concurrent_token_slicer@7

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 37. Reducer: line_based_concurrent_token_slicer@8

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 38. Reducer: line_based_concurrent_token_slicer@9

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 39. Reducer: line_based_concurrent_token_slicer@10

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 40. Reducer: line_based_concurrent_token_slicer@11

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 41. Reducer: line_based_concurrent_token_slicer@12

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 42. Reducer: line_based_concurrent_token_slicer@13

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=Fixpoint iteration 43. Reducer: line_based_concurrent_token_slicer@14

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


========Fixpoint iteration 44. Reducer: tree_slicer=========

The spar-tree is the following.
translationUnit {id=474,slot_type=translationUnit}
|___(+) {id=475,slot_type=kleene_plus__translationUnit_3}
    |___functionDefinition {id=477,slot_type=[aux_rule__translationUnit_2,functionDefinition]}
        |___Token:printf {id=536,slot_type=[declarator,directDeclarator,aux_rule__directDeclarator_9,Identifier]}
        |___compoundStatement {id=479,slot_type=compoundStatement}
            |___Token:{ {id=480,slot_type=LeftBrace}
            |___(?) {id=481,slot_type=optional__compoundStatement_1}
            |   |___(+) {id=484,slot_type=[blockItemList,kleene_plus__blockItemList_3]}
            |       |___expressionStatement {id=488,slot_type=[aux_rule__blockItemList_2,statement,aux_rule__statement_3,expressionStatement]}
            |           |___(?) {id=489,slot_type=optional__postfixExpression_1}
            |           |   |___aux_rule__postfixExpression_13 {id=509,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,aux_rule__postfixExpression_13]}
            |           |       |___aux_rule__primaryExpression_4 {id=512,slot_type=[altnt_block__primaryExpression_3,aux_rule__primaryExpression_4]}
            |           |       |   |___Token:( {id=513,slot_type=LeftParen}
            |           |       |   |___(+) {id=532,slot_type=[expression,assignmentExpression,conditionalExpression,logicalOrExpression,logicalAndExpression,inclusiveOrExpression,exclusiveOrExpression,andExpression,equalityExpression,relationalExpression,shiftExpression,additiveExpression,multiplicativeExpression,castExpression,unaryExpression,aux_rule__unaryExpression_3,postfixExpression,aux_rule__postfixExpression_4,kleene_plus__primaryExpression_1]}
            |           |       |       |___Token:"world\n" {id=533,slot_type=StringLiteral}
            |           |       |___Token:) {id=511,slot_type=RightParen}
            |           |___Token:; {id=490,slot_type=Semi}
            |___Token:} {id=482,slot_type=RightBrace}
------------------------------------------------------------


=================Reducing node 475, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 475
------------------------------------------------------------


=================Reducing node 477, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 477
------------------------------------------------------------


=================Reducing node 479, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 479
------------------------------------------------------------


=================Reducing node 536, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 536
------------------------------------------------------------


=================Reducing node 482, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 482
------------------------------------------------------------


=================Reducing node 481, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: tree_slicer
    --file: t.c--
        printf
                                      {
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 481
------------------------------------------------------------


=================Reducing node 480, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 480
------------------------------------------------------------


=================Reducing node 484, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: tree_slicer
    --file: t.c--
        printf
                                      {
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 484
------------------------------------------------------------


=================Reducing node 488, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: tree_slicer
    --file: t.c--
        printf
                                      {
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 488
------------------------------------------------------------


=================Reducing node 490, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 490
------------------------------------------------------------


=================Reducing node 489, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: tree_slicer
    --file: t.c--
        printf
                                      {
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 489
------------------------------------------------------------


=================Reducing node 509, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


============Testing the following program: fail=============

// edit action set type: tree_slicer
    --file: t.c--
        printf
                                      {
                ;
    }
    --file: <formatted tokenized program in its original format>--
        printf
                                      {
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 509
------------------------------------------------------------


=================Reducing node 511, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 511
------------------------------------------------------------


=================Reducing node 512, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 512
------------------------------------------------------------


=================Reducing node 532, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 532
------------------------------------------------------------


=================Reducing node 513, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 513
------------------------------------------------------------


=================Reducing node 533, size=7==================

The current best program is the following

    --file: t.c--
        printf
                                      {
           (
            "world\n")
                ;
    }
------------------------------------------------------------


===================Node reduction is done===================

Failed to reduce node 533
------------------------------------------------------------


The history of the reducer invocation.
[0]: StatsSnapshotEvent
---
stats:
  tokenCount: 56
  characterCount: 133
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[1]: ReducerCallEvent
---
reducer:
  granularity: 1
  shortName: "concurrent_token_slicer@1"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[2]: StatsSnapshotEvent
---
stats:
  tokenCount: 35
  characterCount: 72
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: true

[3]: ReducerCallEvent
---
reducer:
  granularity: 2
  shortName: "concurrent_token_slicer@2"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[4]: StatsSnapshotEvent
---
stats:
  tokenCount: 17
  characterCount: 44
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: true

[5]: ReducerCallEvent
---
reducer:
  granularity: 3
  shortName: "concurrent_token_slicer@3"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[6]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: true

[7]: ReducerCallEvent
---
reducer:
  granularity: 4
  shortName: "concurrent_token_slicer@4"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[8]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[9]: ReducerCallEvent
---
reducer:
  granularity: 5
  shortName: "concurrent_token_slicer@5"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[10]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[11]: ReducerCallEvent
---
reducer:
  granularity: 6
  shortName: "concurrent_token_slicer@6"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[12]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[13]: ReducerCallEvent
---
reducer:
  granularity: 7
  shortName: "concurrent_token_slicer@7"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[14]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[15]: ReducerCallEvent
---
reducer:
  granularity: 8
  shortName: "concurrent_token_slicer@8"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[16]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[17]: ReducerCallEvent
---
reducer:
  granularity: 9
  shortName: "concurrent_token_slicer@9"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[18]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[19]: ReducerCallEvent
---
reducer:
  granularity: 10
  shortName: "concurrent_token_slicer@10"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[20]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[21]: ReducerCallEvent
---
reducer:
  granularity: 11
  shortName: "concurrent_token_slicer@11"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[22]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[23]: ReducerCallEvent
---
reducer:
  granularity: 12
  shortName: "concurrent_token_slicer@12"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[24]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[25]: ReducerCallEvent
---
reducer:
  granularity: 13
  shortName: "concurrent_token_slicer@13"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[26]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[27]: ReducerCallEvent
---
reducer:
  granularity: 14
  shortName: "concurrent_token_slicer@14"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[28]: StatsSnapshotEvent
---
stats:
  tokenCount: 8
  characterCount: 23
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[29]: ReducerCallEvent
---
reducer:
  granularity: 1
  shortName: "concurrent_token_slicer@1"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[30]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: true

[31]: ReducerCallEvent
---
reducer:
  granularity: 2
  shortName: "concurrent_token_slicer@2"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[32]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[33]: ReducerCallEvent
---
reducer:
  granularity: 3
  shortName: "concurrent_token_slicer@3"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[34]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[35]: ReducerCallEvent
---
reducer:
  granularity: 4
  shortName: "concurrent_token_slicer@4"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[36]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[37]: ReducerCallEvent
---
reducer:
  granularity: 5
  shortName: "concurrent_token_slicer@5"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[38]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[39]: ReducerCallEvent
---
reducer:
  granularity: 6
  shortName: "concurrent_token_slicer@6"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[40]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[41]: ReducerCallEvent
---
reducer:
  granularity: 7
  shortName: "concurrent_token_slicer@7"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[42]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[43]: ReducerCallEvent
---
reducer:
  granularity: 8
  shortName: "concurrent_token_slicer@8"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[44]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[45]: ReducerCallEvent
---
reducer:
  granularity: 9
  shortName: "concurrent_token_slicer@9"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[46]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[47]: ReducerCallEvent
---
reducer:
  granularity: 10
  shortName: "concurrent_token_slicer@10"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[48]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[49]: ReducerCallEvent
---
reducer:
  granularity: 11
  shortName: "concurrent_token_slicer@11"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[50]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[51]: ReducerCallEvent
---
reducer:
  granularity: 12
  shortName: "concurrent_token_slicer@12"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[52]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[53]: ReducerCallEvent
---
reducer:
  granularity: 13
  shortName: "concurrent_token_slicer@13"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[54]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[55]: ReducerCallEvent
---
reducer:
  granularity: 14
  shortName: "concurrent_token_slicer@14"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[56]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[57]: ReducerCallEvent
---
reducer:
  granularity: 1
  shortName: "concurrent_token_slicer@1"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[58]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[59]: ReducerCallEvent
---
reducer:
  granularity: 2
  shortName: "concurrent_token_slicer@2"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[60]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[61]: ReducerCallEvent
---
reducer:
  granularity: 3
  shortName: "concurrent_token_slicer@3"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[62]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[63]: ReducerCallEvent
---
reducer:
  granularity: 4
  shortName: "concurrent_token_slicer@4"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[64]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[65]: ReducerCallEvent
---
reducer:
  granularity: 5
  shortName: "concurrent_token_slicer@5"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[66]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[67]: ReducerCallEvent
---
reducer:
  granularity: 6
  shortName: "concurrent_token_slicer@6"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[68]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[69]: ReducerCallEvent
---
reducer:
  granularity: 7
  shortName: "concurrent_token_slicer@7"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[70]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[71]: ReducerCallEvent
---
reducer:
  granularity: 8
  shortName: "concurrent_token_slicer@8"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[72]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[73]: ReducerCallEvent
---
reducer:
  granularity: 9
  shortName: "concurrent_token_slicer@9"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[74]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[75]: ReducerCallEvent
---
reducer:
  granularity: 10
  shortName: "concurrent_token_slicer@10"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[76]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[77]: ReducerCallEvent
---
reducer:
  granularity: 11
  shortName: "concurrent_token_slicer@11"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[78]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[79]: ReducerCallEvent
---
reducer:
  granularity: 12
  shortName: "concurrent_token_slicer@12"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[80]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[81]: ReducerCallEvent
---
reducer:
  granularity: 13
  shortName: "concurrent_token_slicer@13"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[82]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[83]: ReducerCallEvent
---
reducer:
  granularity: 14
  shortName: "concurrent_token_slicer@14"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[84]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[85]: ReducerCallEvent
---
reducer:
  granularity: 1
  shortName: "line_based_concurrent_token_slicer@1"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[86]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[87]: ReducerCallEvent
---
reducer:
  granularity: 2
  shortName: "line_based_concurrent_token_slicer@2"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[88]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[89]: ReducerCallEvent
---
reducer:
  granularity: 3
  shortName: "line_based_concurrent_token_slicer@3"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[90]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[91]: ReducerCallEvent
---
reducer:
  granularity: 4
  shortName: "line_based_concurrent_token_slicer@4"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[92]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[93]: ReducerCallEvent
---
reducer:
  granularity: 5
  shortName: "line_based_concurrent_token_slicer@5"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[94]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[95]: ReducerCallEvent
---
reducer:
  granularity: 6
  shortName: "line_based_concurrent_token_slicer@6"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[96]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[97]: ReducerCallEvent
---
reducer:
  granularity: 7
  shortName: "line_based_concurrent_token_slicer@7"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[98]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[99]: ReducerCallEvent
---
reducer:
  granularity: 8
  shortName: "line_based_concurrent_token_slicer@8"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[100]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[101]: ReducerCallEvent
---
reducer:
  granularity: 9
  shortName: "line_based_concurrent_token_slicer@9"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[102]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[103]: ReducerCallEvent
---
reducer:
  granularity: 10
  shortName: "line_based_concurrent_token_slicer@10"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[104]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[105]: ReducerCallEvent
---
reducer:
  granularity: 11
  shortName: "line_based_concurrent_token_slicer@11"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[106]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[107]: ReducerCallEvent
---
reducer:
  granularity: 12
  shortName: "line_based_concurrent_token_slicer@12"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[108]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[109]: ReducerCallEvent
---
reducer:
  granularity: 13
  shortName: "line_based_concurrent_token_slicer@13"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[110]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[111]: ReducerCallEvent
---
reducer:
  granularity: 14
  shortName: "line_based_concurrent_token_slicer@14"
  description: "line-based concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "line_based_concurrent_token_slicer"

[112]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[113]: ReducerCallEvent
---
reducer:
  shortName: "tree_slicer"
  description: ""
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"

[114]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[115]: ReducerCallEvent
---
reducer:
  granularity: 1
  shortName: "concurrent_token_slicer@1"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[116]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[117]: ReducerCallEvent
---
reducer:
  granularity: 2
  shortName: "concurrent_token_slicer@2"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[118]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[119]: ReducerCallEvent
---
reducer:
  granularity: 3
  shortName: "concurrent_token_slicer@3"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[120]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[121]: ReducerCallEvent
---
reducer:
  granularity: 4
  shortName: "concurrent_token_slicer@4"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[122]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[123]: ReducerCallEvent
---
reducer:
  granularity: 5
  shortName: "concurrent_token_slicer@5"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[124]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[125]: ReducerCallEvent
---
reducer:
  granularity: 6
  shortName: "concurrent_token_slicer@6"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[126]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[127]: ReducerCallEvent
---
reducer:
  granularity: 7
  shortName: "concurrent_token_slicer@7"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[128]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[129]: ReducerCallEvent
---
reducer:
  granularity: 8
  shortName: "concurrent_token_slicer@8"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[130]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[131]: ReducerCallEvent
---
reducer:
  granularity: 9
  shortName: "concurrent_token_slicer@9"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[132]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[133]: ReducerCallEvent
---
reducer:
  granularity: 10
  shortName: "concurrent_token_slicer@10"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[134]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[135]: ReducerCallEvent
---
reducer:
  granularity: 11
  shortName: "concurrent_token_slicer@11"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[136]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[137]: ReducerCallEvent
---
reducer:
  granularity: 12
  shortName: "concurrent_token_slicer@12"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[138]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[139]: ReducerCallEvent
---
reducer:
  granularity: 13
  shortName: "concurrent_token_slicer@13"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[140]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false

[141]: ReducerCallEvent
---
reducer:
  granularity: 14
  shortName: "concurrent_token_slicer@14"
  description: "concurrent token slicer"
  deterministic: true
  reductionResultSizeTrend: "BEST_RESULT_SIZE_DECREASE"
  namePrefix: "concurrent_token_slicer"

[142]: StatsSnapshotEvent
---
stats:
  tokenCount: 7
  characterCount: 20
  fileContents:
  - fileName: "t.c"
    contentDigest:
      digest: {}
      numOfStrings: 1
numberOfNonDeletionIterations: 0
fileContentChangedWrtPrevious: false


#test success = 34
#test failure = 133
#test result cache hits = 0
#test execution cancelled = 0
#node edit action set cache hits = 0
#external test execution cache hits = 0
